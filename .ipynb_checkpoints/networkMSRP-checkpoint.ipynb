{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdEi2yFVjcEs"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ENru5ixojhTY",
    "outputId": "b473f3f2-f231-45ad-c6a3-c630630a74e2"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zsh5PhS8jyC4",
    "outputId": "dc2587a0-ef95-48c8-8c57-ba2478b1d390"
   },
   "outputs": [],
   "source": [
    "#cd drive/My Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GOL_xMwHj4NQ",
    "outputId": "083de693-2875-4dcc-c75c-f3eabb6a0897"
   },
   "outputs": [],
   "source": [
    "#cd maLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uSRaRsjPjhbq"
   },
   "outputs": [],
   "source": [
    "from data import Data\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "HYTshg6ZjcEv",
    "outputId": "973ec3d0-3687-4cd6-9fdf-e0e531387bf7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HERSH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXhQ1uUejcEx"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JN1k4zlpjcE0"
   },
   "outputs": [],
   "source": [
    "data_name = \"msrp\"\n",
    "data_file = \"./dataset/train.tsv\"\n",
    "training_ratio = 0.8\n",
    "max_len = 20\n",
    "tracking_pair = False\n",
    "hidden_size = 50\n",
    "batch_size = 16\n",
    "num_iters = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "5dokmAXejcE2",
    "outputId": "73af916d-809c-4086-b6d9-2f7bea43ca80"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'questions_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0e56a8de7711>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_ratio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\MSRP\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_name, data_file, train_ratio, max_len, vocab_limit, sentence_cols, score_col)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_col\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquestions_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'questions_cols' is not defined"
     ]
    }
   ],
   "source": [
    "data = Data(data_name,data_file,training_ratio,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 16834
    },
    "colab_type": "code",
    "id": "lHFnXIKfjcE6",
    "outputId": "32be1f6b-2bc5-4897-90c7-6b629f9fdcc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PAD': 0,\n",
       " 'a': 1,\n",
       " 'group': 2,\n",
       " 'of': 3,\n",
       " 'kids': 4,\n",
       " 'is': 5,\n",
       " 'playing': 6,\n",
       " 'in': 7,\n",
       " 'yard': 8,\n",
       " 'and': 9,\n",
       " 'an': 10,\n",
       " 'old': 11,\n",
       " 'man': 12,\n",
       " 'standing': 13,\n",
       " 'the': 14,\n",
       " 'background': 15,\n",
       " 'boys': 16,\n",
       " 'children': 17,\n",
       " 'house': 18,\n",
       " 'there': 19,\n",
       " 'no': 20,\n",
       " 'young': 21,\n",
       " 'are': 22,\n",
       " 'outdoors': 23,\n",
       " 'smiling': 24,\n",
       " 'nearby': 25,\n",
       " 'near': 26,\n",
       " 'with': 27,\n",
       " 'smile': 28,\n",
       " 'boy': 29,\n",
       " 'brown': 30,\n",
       " 'dog': 31,\n",
       " 'attacking': 32,\n",
       " 'another': 33,\n",
       " 'animal': 34,\n",
       " 'front': 35,\n",
       " 'tall': 36,\n",
       " 'pants': 37,\n",
       " 'helping': 38,\n",
       " 'two': 39,\n",
       " 'dogs': 40,\n",
       " 'fighting': 41,\n",
       " 'wrestling': 42,\n",
       " 'hugging': 43,\n",
       " 'person': 44,\n",
       " 'black': 45,\n",
       " 'jacket': 46,\n",
       " 'doing': 47,\n",
       " 'tricks': 48,\n",
       " 'on': 49,\n",
       " 'motorbike': 50,\n",
       " 'skilled': 51,\n",
       " 'riding': 52,\n",
       " 'bicycle': 53,\n",
       " 'one': 54,\n",
       " 'wheel': 55,\n",
       " 'nobody': 56,\n",
       " 'jersey': 57,\n",
       " 'dunking': 58,\n",
       " 'ball': 59,\n",
       " 'at': 60,\n",
       " 'basketball': 61,\n",
       " 'game': 62,\n",
       " 'being': 63,\n",
       " 'dunked': 64,\n",
       " 'by': 65,\n",
       " 'consists': 66,\n",
       " 'who': 67,\n",
       " 'dunks': 68,\n",
       " 'into': 69,\n",
       " 'net': 70,\n",
       " 'crowd': 71,\n",
       " 'player': 72,\n",
       " 'missing': 73,\n",
       " 'basket': 74,\n",
       " 'people': 75,\n",
       " 'kickboxing': 76,\n",
       " 'spectators': 77,\n",
       " 'watching': 78,\n",
       " 'not': 79,\n",
       " 'some': 80,\n",
       " 'women': 81,\n",
       " 'sparring': 82,\n",
       " 'fight': 83,\n",
       " 'match': 84,\n",
       " 'red': 85,\n",
       " 'shirts': 86,\n",
       " 'leaves': 87,\n",
       " 'sleeping': 88,\n",
       " 'covered': 89,\n",
       " 'three': 90,\n",
       " 'jumping': 91,\n",
       " 'sitting': 92,\n",
       " 'lying': 93,\n",
       " 'snow': 94,\n",
       " 'drawing': 95,\n",
       " 'angels': 96,\n",
       " 'making': 97,\n",
       " 'child': 98,\n",
       " 'wearing': 99,\n",
       " 'snowsuits': 100,\n",
       " 'ground': 101,\n",
       " 'little': 102,\n",
       " 'girl': 103,\n",
       " 'looking': 104,\n",
       " 'woman': 105,\n",
       " 'costume': 106,\n",
       " 'looks': 107,\n",
       " 'like': 108,\n",
       " 'costumes': 109,\n",
       " 'gathering': 110,\n",
       " 'forest': 111,\n",
       " 'same': 112,\n",
       " 'direction': 113,\n",
       " 'masked': 114,\n",
       " 'scattering': 115,\n",
       " 'different': 116,\n",
       " 'directions': 117,\n",
       " 'gathered': 118,\n",
       " 'vicinity': 119,\n",
       " 'lone': 120,\n",
       " 'biker': 121,\n",
       " 'air': 122,\n",
       " 'alone': 123,\n",
       " 'empty': 124,\n",
       " 'swimming': 125,\n",
       " 'pool': 126,\n",
       " 'full': 127,\n",
       " 'jumper': 128,\n",
       " 'four': 129,\n",
       " 'backbends': 130,\n",
       " 'park': 131,\n",
       " 'gym': 132,\n",
       " 'girls': 133,\n",
       " 'garden': 134,\n",
       " 'indoors': 135,\n",
       " 'running': 136,\n",
       " 'his': 137,\n",
       " 'hands': 138,\n",
       " 'throwing': 139,\n",
       " 'groups': 140,\n",
       " 'football': 141,\n",
       " 'teams': 142,\n",
       " 'competing': 143,\n",
       " 'baseball': 144,\n",
       " 'played': 145,\n",
       " 'five': 146,\n",
       " 'wooden': 147,\n",
       " 'hut': 148,\n",
       " 'made': 149,\n",
       " 'wood': 150,\n",
       " 'stands': 151,\n",
       " 'each': 152,\n",
       " 'close': 153,\n",
       " 'together': 154,\n",
       " 'kid': 155,\n",
       " 'has': 156,\n",
       " 'gun': 157,\n",
       " 'weapon': 158,\n",
       " 'none': 159,\n",
       " 'field': 160,\n",
       " 'hat': 161,\n",
       " 'grass': 162,\n",
       " 'current': 163,\n",
       " 'ridden': 164,\n",
       " 'friends': 165,\n",
       " 'raft': 166,\n",
       " 'this': 167,\n",
       " 'practicing': 168,\n",
       " 'water': 169,\n",
       " 'safety': 170,\n",
       " 'preservers': 171,\n",
       " 'worn': 172,\n",
       " 'deer': 173,\n",
       " 'over': 174,\n",
       " 'fence': 175,\n",
       " 'enclosure': 176,\n",
       " 'wild': 177,\n",
       " 'fences': 178,\n",
       " 'walking': 179,\n",
       " 'outside': 180,\n",
       " 'building': 181,\n",
       " 'that': 182,\n",
       " 'many': 183,\n",
       " 'murals': 184,\n",
       " 'it': 185,\n",
       " 'several': 186,\n",
       " 'inside': 187,\n",
       " 'which': 188,\n",
       " 'colors': 189,\n",
       " 'colorful': 190,\n",
       " 'hitting': 191,\n",
       " 'family': 192,\n",
       " 'large': 193,\n",
       " 'asian': 194,\n",
       " 'eating': 195,\n",
       " 'restaurant': 196,\n",
       " 'from': 197,\n",
       " 'asia': 198,\n",
       " 'small': 199,\n",
       " 'waiting': 200,\n",
       " 'to': 201,\n",
       " 'eat': 202,\n",
       " 'various': 203,\n",
       " 'tables': 204,\n",
       " 'crowded': 205,\n",
       " 'purple': 206,\n",
       " 'lights': 207,\n",
       " 'customers': 208,\n",
       " 'few': 209,\n",
       " 'without': 210,\n",
       " 'lit': 211,\n",
       " 'motorcycle': 212,\n",
       " 'rider': 213,\n",
       " 'up': 214,\n",
       " 'seat': 215,\n",
       " 'white': 216,\n",
       " 'vehicle': 217,\n",
       " 'someone': 218,\n",
       " 'bike': 219,\n",
       " 'motorcyclist': 220,\n",
       " 'dangerously': 221,\n",
       " 'along': 222,\n",
       " 'roadway': 223,\n",
       " 'helmet': 224,\n",
       " 'painted': 225,\n",
       " 'blue': 226,\n",
       " 'down': 227,\n",
       " 'road': 228,\n",
       " 'catching': 229,\n",
       " 'stick': 230,\n",
       " 'leaping': 231,\n",
       " 'high': 232,\n",
       " 'tree': 233,\n",
       " 'plant': 234,\n",
       " 'dancing': 235,\n",
       " 'clothes': 236,\n",
       " 'dancer': 237,\n",
       " 'sound': 238,\n",
       " 'equipment': 239,\n",
       " 'blond': 240,\n",
       " 'behind': 241,\n",
       " 'patiently': 242,\n",
       " 'serious': 243,\n",
       " 'egyptian': 244,\n",
       " 'her': 245,\n",
       " 'head': 246,\n",
       " 'headdress': 247,\n",
       " 'indian': 248,\n",
       " 'glasses': 249,\n",
       " 'sunglasses': 250,\n",
       " 'or': 251,\n",
       " 'hiker': 252,\n",
       " 'top': 253,\n",
       " 'mountain': 254,\n",
       " 'joyful': 255,\n",
       " 'dance': 256,\n",
       " 'rock': 257,\n",
       " 'above': 258,\n",
       " 'trees': 259,\n",
       " 'uncomfortable': 260,\n",
       " 'position': 261,\n",
       " 'strange': 262,\n",
       " 'cowgirl': 263,\n",
       " 'horse': 264,\n",
       " 'cornering': 265,\n",
       " 'barrel': 266,\n",
       " 'corners': 267,\n",
       " 'cowboy': 268,\n",
       " 'corner': 269,\n",
       " 'very': 270,\n",
       " 'rodeo': 271,\n",
       " 'far': 272,\n",
       " 'cold': 273,\n",
       " 'through': 274,\n",
       " 'ocean': 275,\n",
       " 'wading': 276,\n",
       " 'guitar': 277,\n",
       " 'stage': 278,\n",
       " 'blonde': 279,\n",
       " 'flyaway': 280,\n",
       " 'hair': 281,\n",
       " 'guitarist': 282,\n",
       " 'bald': 283,\n",
       " 'have': 284,\n",
       " 'their': 285,\n",
       " 'knees': 286,\n",
       " 'raised': 287,\n",
       " 'raising': 288,\n",
       " 'nude': 289,\n",
       " 'lady': 290,\n",
       " 'body': 291,\n",
       " 'paint': 292,\n",
       " 'topless': 293,\n",
       " 'uniforms': 294,\n",
       " 'gate': 295,\n",
       " 'kissing': 296,\n",
       " 'mother': 297,\n",
       " 'mothers': 298,\n",
       " 'parking': 299,\n",
       " 'lot': 300,\n",
       " 'tennis': 301,\n",
       " 'against': 302,\n",
       " 'wall': 303,\n",
       " 'friend': 304,\n",
       " 'pointing': 305,\n",
       " 'silver': 306,\n",
       " 'sedan': 307,\n",
       " 'car': 308,\n",
       " 'beach': 309,\n",
       " 'sea': 310,\n",
       " 'schoolgirl': 311,\n",
       " 'bag': 312,\n",
       " 'train': 313,\n",
       " 'cramped': 314,\n",
       " 'carrying': 315,\n",
       " 'midst': 316,\n",
       " 'chasing': 317,\n",
       " 'holding': 318,\n",
       " 'its': 319,\n",
       " 'mouth': 320,\n",
       " 'piece': 321,\n",
       " 'toy': 322,\n",
       " 'mouths': 323,\n",
       " 'object': 324,\n",
       " 'dirty': 325,\n",
       " 'soccer': 326,\n",
       " 'rolling': 327,\n",
       " 'goal': 328,\n",
       " 'plays': 329,\n",
       " 'kicking': 330,\n",
       " 'out': 331,\n",
       " 'resting': 332,\n",
       " 'chair': 333,\n",
       " 'rubbing': 334,\n",
       " 'eyes': 335,\n",
       " 'tattoos': 336,\n",
       " 'lounging': 337,\n",
       " 'couch': 338,\n",
       " 'pencil': 339,\n",
       " 'tattooed': 340,\n",
       " 'sofa': 341,\n",
       " 'for': 342,\n",
       " 'moving': 343,\n",
       " 'tan': 344,\n",
       " 'green': 345,\n",
       " 'low': 346,\n",
       " 'busy': 347,\n",
       " 'area': 348,\n",
       " 'writing': 349,\n",
       " 'something': 350,\n",
       " 'note': 351,\n",
       " 'paper': 352,\n",
       " 'scouts': 353,\n",
       " 'hiking': 354,\n",
       " 'explorers': 355,\n",
       " 'camping': 356,\n",
       " 'men': 357,\n",
       " 'taking': 358,\n",
       " 'break': 359,\n",
       " 'trip': 360,\n",
       " 'snowy': 361,\n",
       " 'breaking': 362,\n",
       " 'during': 363,\n",
       " 'bikes': 364,\n",
       " 'side': 365,\n",
       " 'cars': 366,\n",
       " 'fishing': 367,\n",
       " 'poles': 368,\n",
       " 'tackle': 369,\n",
       " 'tools': 370,\n",
       " 'used': 371,\n",
       " 'helmeted': 372,\n",
       " 'perching': 373,\n",
       " 'performing': 374,\n",
       " 'trick': 375,\n",
       " 'ramp': 376,\n",
       " 'blonds': 377,\n",
       " 'surfing': 378,\n",
       " 'waves': 379,\n",
       " 'while': 380,\n",
       " 'she': 381,\n",
       " 'wave': 382,\n",
       " 'adult': 383,\n",
       " 'next': 384,\n",
       " 'limb': 385,\n",
       " 'hanging': 386,\n",
       " 'branch': 387,\n",
       " 'climbing': 388,\n",
       " 'dressed': 389,\n",
       " 'stunts': 390,\n",
       " 'squirt': 391,\n",
       " 'laughing': 392,\n",
       " 'getting': 393,\n",
       " 'sprayed': 394,\n",
       " 'sprays': 395,\n",
       " 'hit': 396,\n",
       " 'other': 397,\n",
       " 'daschunds': 398,\n",
       " 'cats': 399,\n",
       " 'stand': 400,\n",
       " 'barks': 401,\n",
       " 'him': 402,\n",
       " 'sprinting': 403,\n",
       " 'owns': 404,\n",
       " 'trying': 405,\n",
       " 'catch': 406,\n",
       " 'owner': 407,\n",
       " 'slowing': 408,\n",
       " 'quitting': 409,\n",
       " 'comfortably': 410,\n",
       " 'table': 411,\n",
       " 'comfortable': 412,\n",
       " 'discussion': 413,\n",
       " 'dyed': 414,\n",
       " 'shirt': 415,\n",
       " 'dyeing': 416,\n",
       " 'you': 417,\n",
       " 'cannot': 418,\n",
       " 'sit': 419,\n",
       " 'pink': 420,\n",
       " 'boa': 421,\n",
       " 'bridge': 422,\n",
       " 'built': 423,\n",
       " 'pedestrians': 424,\n",
       " 'scarf': 425,\n",
       " 'off': 426,\n",
       " 'stopping': 427,\n",
       " 'pedestrian': 428,\n",
       " 'bicycles': 429,\n",
       " 'riders': 430,\n",
       " 'bellbottoms': 431,\n",
       " 'happily': 432,\n",
       " 'be': 433,\n",
       " 'gear': 434,\n",
       " 'naked': 435,\n",
       " 'gears': 436,\n",
       " 'pushing': 437,\n",
       " 'towards': 438,\n",
       " 'grey': 439,\n",
       " 't': 440,\n",
       " '-': 441,\n",
       " 'waterfall': 442,\n",
       " 'rocker': 443,\n",
       " 'somebody': 444,\n",
       " 'racing': 445,\n",
       " 'dark': 446,\n",
       " 'light': 447,\n",
       " 'back': 448,\n",
       " 'backyard': 449,\n",
       " 'coat': 450,\n",
       " 'trotting': 451,\n",
       " 'shallow': 452,\n",
       " 'colored': 453,\n",
       " 'floating': 454,\n",
       " 'across': 455,\n",
       " 'difficulty': 456,\n",
       " 'pacing': 457,\n",
       " 'door': 458,\n",
       " 'bunch': 459,\n",
       " 'quiet': 460,\n",
       " 'cloak': 461,\n",
       " 'revealing': 462,\n",
       " 'extravagant': 463,\n",
       " 'dress': 464,\n",
       " 'apparel': 465,\n",
       " 'putting': 466,\n",
       " 'concealing': 467,\n",
       " 'teenage': 468,\n",
       " 'beads': 469,\n",
       " 'storing': 470,\n",
       " 'away': 471,\n",
       " 'likes': 472,\n",
       " 'teenagers': 473,\n",
       " 'necklace': 474,\n",
       " 'sweatshirt': 475,\n",
       " 'earrings': 476,\n",
       " 'age': 477,\n",
       " 'upon': 478,\n",
       " 'suited': 479,\n",
       " 'artificially': 480,\n",
       " 'attached': 481,\n",
       " 'rope': 482,\n",
       " 'effortlessly': 483,\n",
       " 'coming': 484,\n",
       " 'climber': 485,\n",
       " 'fearful': 486,\n",
       " 'rescues': 487,\n",
       " 'cat': 488,\n",
       " 'dad': 489,\n",
       " 'launching': 490,\n",
       " 'daughter': 491,\n",
       " 'father': 492,\n",
       " 'daughters': 493,\n",
       " 'launch': 494,\n",
       " 'tossing': 495,\n",
       " 'coin': 496,\n",
       " 'cliff': 497,\n",
       " 'descending': 498,\n",
       " 'social': 499,\n",
       " 'tying': 500,\n",
       " 'climbed': 501,\n",
       " 'roped': 502,\n",
       " 'under': 503,\n",
       " 'program': 504,\n",
       " 'about': 505,\n",
       " 'climbers': 506,\n",
       " 'midair': 507,\n",
       " 'failing': 508,\n",
       " 'perform': 509,\n",
       " 'cyclist': 510,\n",
       " 'fearlessly': 511,\n",
       " 'tricking': 512,\n",
       " 'staring': 513,\n",
       " 'street': 514,\n",
       " 'ignoring': 515,\n",
       " 'breeds': 516,\n",
       " 'angrily': 517,\n",
       " 'streets': 518,\n",
       " 'looked': 519,\n",
       " 'probably': 520,\n",
       " 'pine': 521,\n",
       " 'dropping': 522,\n",
       " 'bucket': 523,\n",
       " 'biting': 524,\n",
       " 'furry': 525,\n",
       " 'fur': 526,\n",
       " 'persons': 527,\n",
       " 'size': 528,\n",
       " 'bench': 529,\n",
       " 'they': 530,\n",
       " 'bottle': 531,\n",
       " 'soda': 532,\n",
       " 'between': 533,\n",
       " 'them': 534,\n",
       " 'nothing': 535,\n",
       " 'benches': 536,\n",
       " 'leading': 537,\n",
       " 'race': 538,\n",
       " 'bringing': 539,\n",
       " 'rear': 540,\n",
       " 'lead': 541,\n",
       " 'competition': 542,\n",
       " 'competitions': 543,\n",
       " 'subject': 544,\n",
       " 'studied': 545,\n",
       " 'camera': 546,\n",
       " 'studying': 547,\n",
       " 'study': 548,\n",
       " 'operating': 549,\n",
       " 'makes': 550,\n",
       " 'videos': 551,\n",
       " 'bride': 552,\n",
       " 'groom': 553,\n",
       " 'leaving': 554,\n",
       " 'after': 555,\n",
       " 'marriage': 556,\n",
       " 'wedding': 557,\n",
       " 'arriving': 558,\n",
       " 'married': 559,\n",
       " 'couple': 560,\n",
       " 'aisle': 561,\n",
       " 'just': 562,\n",
       " 'got': 563,\n",
       " 'isle': 564,\n",
       " 'priest': 565,\n",
       " 'marry': 566,\n",
       " 'students': 567,\n",
       " 'filling': 568,\n",
       " 'classroom': 569,\n",
       " 'presentation': 570,\n",
       " 'watched': 571,\n",
       " 'attended': 572,\n",
       " 'hill': 573,\n",
       " 'sliding': 574,\n",
       " 'bottom': 575,\n",
       " 'slide': 576,\n",
       " 'still': 577,\n",
       " 'peacefully': 578,\n",
       " 'stump': 579,\n",
       " 'excitedly': 580,\n",
       " 'watering': 581,\n",
       " 'droplets': 582,\n",
       " 'snapping': 583,\n",
       " 'snap': 584,\n",
       " 'depicting': 585,\n",
       " 'falling': 586,\n",
       " 'golden': 587,\n",
       " 'coats': 588,\n",
       " 'provide': 589,\n",
       " 'camouflage': 590,\n",
       " 'provides': 591,\n",
       " 'brick': 592,\n",
       " 'window': 593,\n",
       " 'surprised': 594,\n",
       " 'bricks': 595,\n",
       " 'does': 596,\n",
       " 'look': 597,\n",
       " 'open': 598,\n",
       " 'keeping': 599,\n",
       " 'equipped': 600,\n",
       " 'protective': 601,\n",
       " 'protection': 602,\n",
       " 'unprotective': 603,\n",
       " 'biking': 604,\n",
       " 'steadily': 605,\n",
       " 'mountains': 606,\n",
       " 'placed': 607,\n",
       " 'feet': 608,\n",
       " 'hiding': 609,\n",
       " 'harmlessly': 610,\n",
       " 'dodge': 611,\n",
       " 'vertical': 612,\n",
       " 'rescue': 613,\n",
       " 'pigtails': 614,\n",
       " 'ponytail': 615,\n",
       " 'tailing': 616,\n",
       " 'pony': 617,\n",
       " 'joyfully': 618,\n",
       " 'cheerfully': 619,\n",
       " 'ice': 620,\n",
       " 'skating': 621,\n",
       " 'rink': 622,\n",
       " 'skater': 623,\n",
       " 'uniform': 624,\n",
       " 'quickly': 625,\n",
       " 'arm': 626,\n",
       " 'lowering': 627,\n",
       " 'cheering': 628,\n",
       " 'cheers': 629,\n",
       " 'performed': 630,\n",
       " 'guys': 631,\n",
       " 'shore': 632,\n",
       " 'sand': 633,\n",
       " 'enjoying': 634,\n",
       " 'sunny': 635,\n",
       " 'day': 636,\n",
       " 'sun': 637,\n",
       " 'suffering': 638,\n",
       " 'jumpsuit': 639,\n",
       " 'wheelie': 640,\n",
       " 'courageously': 641,\n",
       " 'courageous': 642,\n",
       " 'performer': 643,\n",
       " 'mostly': 644,\n",
       " 'barren': 645,\n",
       " 'onto': 646,\n",
       " 'filming': 647,\n",
       " 'done': 648,\n",
       " 'kissed': 649,\n",
       " 'passionately': 650,\n",
       " 'arguing': 651,\n",
       " 'throng': 652,\n",
       " 'blowing': 653,\n",
       " 'bubble': 654,\n",
       " 'huge': 655,\n",
       " 'blew': 656,\n",
       " 'boots': 657,\n",
       " 'rubber': 658,\n",
       " 'puddle': 659,\n",
       " 'mud': 660,\n",
       " 'barefoot': 661,\n",
       " 'past': 662,\n",
       " 'targeted': 663,\n",
       " 'playful': 664,\n",
       " 'corndogs': 665,\n",
       " 'eaten': 666,\n",
       " 'toddlers': 667,\n",
       " 'wagon': 668,\n",
       " 'really': 669,\n",
       " 'fasting': 670,\n",
       " 'funny': 671,\n",
       " 'face': 672,\n",
       " 'dying': 673,\n",
       " 'pose': 674,\n",
       " 'amusedly': 675,\n",
       " 'posing': 676,\n",
       " 'color': 677,\n",
       " 'tossed': 678,\n",
       " 'abruptly': 679,\n",
       " 'track': 680,\n",
       " 'laid': 681,\n",
       " 'laying': 682,\n",
       " 'cover': 683,\n",
       " 'amphitheater': 684,\n",
       " 'talking': 685,\n",
       " 'seriously': 686,\n",
       " 'talk': 687,\n",
       " 'given': 688,\n",
       " 'stairs': 689,\n",
       " 'outdoor': 690,\n",
       " 'long': 691,\n",
       " 'suspiciously': 692,\n",
       " 'eyebrow': 693,\n",
       " 'facing': 694,\n",
       " 'space': 695,\n",
       " 'reserved': 696,\n",
       " 'handicapped': 697,\n",
       " 'jockeys': 698,\n",
       " 'horses': 699,\n",
       " 'completely': 700,\n",
       " 'races': 701,\n",
       " 'furiously': 702,\n",
       " 'obstacle': 703,\n",
       " 'furious': 704,\n",
       " 'racers': 705,\n",
       " 'yelling': 706,\n",
       " 'newspapers': 707,\n",
       " 'both': 708,\n",
       " 'newspaper': 709,\n",
       " 'featuring': 710,\n",
       " 'sized': 711,\n",
       " 'rose': 712,\n",
       " 'patterned': 713,\n",
       " 'clumsily': 714,\n",
       " 'pattern': 715,\n",
       " 'shirtless': 716,\n",
       " 'snowboarding': 717,\n",
       " 'jumps': 718,\n",
       " 'falls': 719,\n",
       " 'snowboard': 720,\n",
       " 'snowboarder': 721,\n",
       " 'leap': 722,\n",
       " 'greatly': 723,\n",
       " 'appealing': 724,\n",
       " 'snowboarders': 725,\n",
       " 'tirelessly': 726,\n",
       " 'sandy': 727,\n",
       " 'event': 728,\n",
       " 'related': 729,\n",
       " 'motocross': 730,\n",
       " 'giving': 731,\n",
       " 'peaceful': 732,\n",
       " 'found': 733,\n",
       " 'teach': 734,\n",
       " 'run': 735,\n",
       " 'gray': 736,\n",
       " 'difficultly': 737,\n",
       " 'opening': 738,\n",
       " 'package': 739,\n",
       " 'contains': 740,\n",
       " 'headphones': 741,\n",
       " 'contain': 742,\n",
       " 'singing': 743,\n",
       " 'song': 744,\n",
       " 'skateboard': 745,\n",
       " 'turtle': 746,\n",
       " 'hunting': 747,\n",
       " 'fish': 748,\n",
       " 'food': 749,\n",
       " 'following': 750,\n",
       " 'driving': 751,\n",
       " 'driven': 752,\n",
       " 'dipping': 753,\n",
       " 'prawn': 754,\n",
       " 'batter': 755,\n",
       " 'shrimp': 756,\n",
       " 'windows': 757,\n",
       " 'piano': 758,\n",
       " 'concert': 759,\n",
       " 'adding': 760,\n",
       " 'ingredients': 761,\n",
       " 'big': 762,\n",
       " 'bowl': 763,\n",
       " 'removing': 764,\n",
       " 'cracking': 765,\n",
       " 'eggs': 766,\n",
       " 'container': 767,\n",
       " 'slicing': 768,\n",
       " 'carrot': 769,\n",
       " 'sliced': 770,\n",
       " 'potato': 771,\n",
       " 'cooking': 772,\n",
       " 'prawns': 773,\n",
       " 'boiling': 774,\n",
       " 'shrimps': 775,\n",
       " 'combing': 776,\n",
       " 'arranging': 777,\n",
       " 'wooded': 778,\n",
       " 'desert': 779,\n",
       " 'areas': 780,\n",
       " 'woods': 781,\n",
       " 'city': 782,\n",
       " 'speech': 783,\n",
       " 'podium': 784,\n",
       " 'speaking': 785,\n",
       " 'where': 786,\n",
       " 'tanking': 787,\n",
       " 'telephonic': 788,\n",
       " 'device': 789,\n",
       " 'telephone': 790,\n",
       " 'frightened': 791,\n",
       " 'phone': 792,\n",
       " 'monkey': 793,\n",
       " 'marsh': 794,\n",
       " 'river': 795,\n",
       " 'bun': 796,\n",
       " 'cutting': 797,\n",
       " 'tomato': 798,\n",
       " 'rain': 799,\n",
       " 'peel': 800,\n",
       " 'peeling': 801,\n",
       " 'amalgamating': 802,\n",
       " 'mixing': 803,\n",
       " 'hungry': 804,\n",
       " 'drinking': 805,\n",
       " 'band': 806,\n",
       " 'onstage': 807,\n",
       " 'shaking': 808,\n",
       " 'drink': 809,\n",
       " 'mowing': 810,\n",
       " 'lawn': 811,\n",
       " 'gracefully': 812,\n",
       " 'swinging': 813,\n",
       " 'fan': 814,\n",
       " 'stuck': 815,\n",
       " 'ceiling': 816,\n",
       " 'music': 817,\n",
       " 'flute': 818,\n",
       " 'frying': 819,\n",
       " 'tortilla': 820,\n",
       " 'card': 821,\n",
       " 'cards': 822,\n",
       " 'spanking': 823,\n",
       " 'plastic': 824,\n",
       " 'sword': 825,\n",
       " 'whacking': 826,\n",
       " 'measuring': 827,\n",
       " 'ankle': 828,\n",
       " 'measured': 829,\n",
       " 'call': 830,\n",
       " 'cell': 831,\n",
       " 'cute': 832,\n",
       " 'puppy': 833,\n",
       " 'repeatedly': 834,\n",
       " 'machine': 835,\n",
       " 'sharpening': 836,\n",
       " 'sharpened': 837,\n",
       " 'knife': 838,\n",
       " 'shaving': 839,\n",
       " 'end': 840,\n",
       " 'shaved': 841,\n",
       " 'keyboard': 842,\n",
       " 'pianist': 843,\n",
       " 'rinsing': 844,\n",
       " 'steak': 845,\n",
       " 'meat': 846,\n",
       " 'rinsed': 847,\n",
       " 'chopping': 848,\n",
       " 'onion': 849,\n",
       " 'sad': 850,\n",
       " 'crying': 851,\n",
       " 'screaming': 852,\n",
       " 'scared': 853,\n",
       " 'butter': 854,\n",
       " 'chopped': 855,\n",
       " 'cut': 856,\n",
       " 'sawing': 857,\n",
       " 'logs': 858,\n",
       " 'washing': 859,\n",
       " 'brushing': 860,\n",
       " 'hand': 861,\n",
       " 'musician': 862,\n",
       " 'electric': 863,\n",
       " 'spitting': 864,\n",
       " 'radio': 865,\n",
       " 'spreading': 866,\n",
       " 'dough': 867,\n",
       " 'spread': 868,\n",
       " 'lumping': 869,\n",
       " 'sharp': 870,\n",
       " 'happy': 871,\n",
       " 'baby': 872,\n",
       " 'exercising': 873,\n",
       " 'physical': 874,\n",
       " 'activity': 875,\n",
       " 'vending': 876,\n",
       " 'cyclone': 877,\n",
       " 'oil': 878,\n",
       " 'stirred': 879,\n",
       " 'stirring': 880,\n",
       " 'sauce': 881,\n",
       " 'chicken': 882,\n",
       " 'strumming': 883,\n",
       " 'karate': 884,\n",
       " 'circle': 885,\n",
       " 'ping': 886,\n",
       " 'pong': 887,\n",
       " 'broccoli': 888,\n",
       " 'vegetables': 889,\n",
       " 'flowers': 890,\n",
       " 'plants': 891,\n",
       " 'planting': 892,\n",
       " 'keyboards': 893,\n",
       " 'mimes': 894,\n",
       " 'acting': 895,\n",
       " 'picking': 896,\n",
       " 'picked': 897,\n",
       " 'trumpet': 898,\n",
       " 'listening': 899,\n",
       " 'badger': 900,\n",
       " 'burrowing': 901,\n",
       " 'hole': 902,\n",
       " 'burrowed': 903,\n",
       " 'shrewd': 904,\n",
       " 'digging': 905,\n",
       " 'earth': 906,\n",
       " 'shrewdly': 907,\n",
       " 'liquid': 908,\n",
       " 'poured': 909,\n",
       " 'pan': 910,\n",
       " 'pouring': 911,\n",
       " 'pot': 912,\n",
       " 'chef': 913,\n",
       " 'carefully': 914,\n",
       " 'drying': 915,\n",
       " 'typing': 916,\n",
       " 'stenography': 917,\n",
       " 'stenograph': 918,\n",
       " 'cautiously': 919,\n",
       " 'needs': 920,\n",
       " 'operate': 921,\n",
       " 'snake': 922,\n",
       " 'fed': 923,\n",
       " 'mouse': 924,\n",
       " 'feeding': 925,\n",
       " 'poor': 926,\n",
       " 'snakes': 927,\n",
       " 'mice': 928,\n",
       " 'guy': 929,\n",
       " 'footbag': 930,\n",
       " 'austerely': 931,\n",
       " 'mixed': 932,\n",
       " 'separated': 933,\n",
       " 'bowling': 934,\n",
       " 'mixer': 935,\n",
       " 'vigorously': 936,\n",
       " 'recklessly': 937,\n",
       " 'riskily': 938,\n",
       " 'slowly': 939,\n",
       " 'peeled': 940,\n",
       " 'boat': 941,\n",
       " 'sailing': 942,\n",
       " 'quietly': 943,\n",
       " 'anchored': 944,\n",
       " 'sail': 945,\n",
       " 'reflected': 946,\n",
       " 'tomatoes': 947,\n",
       " 'pours': 948,\n",
       " 'milk': 949,\n",
       " 'drunk': 950,\n",
       " 'milking': 951,\n",
       " 'kitten': 952,\n",
       " 'fresh': 953,\n",
       " 'emptying': 954,\n",
       " 'frog': 955,\n",
       " 'held': 956,\n",
       " 'carelessly': 957,\n",
       " 'slices': 958,\n",
       " 'elephant': 959,\n",
       " 'anyone': 960,\n",
       " 'buttons': 961,\n",
       " 'microwave': 962,\n",
       " 'pushed': 963,\n",
       " 'toward': 964,\n",
       " 'turning': 965,\n",
       " 'powering': 966,\n",
       " 'lovely': 967,\n",
       " 'way': 968,\n",
       " 'put': 969,\n",
       " 'play': 970,\n",
       " 'tough': 971,\n",
       " 'cheetah': 972,\n",
       " 'breathlessly': 973,\n",
       " 'prey': 974,\n",
       " 'shaken': 975,\n",
       " 'lion': 976,\n",
       " 'tiredly': 977,\n",
       " 'pen': 978,\n",
       " 'tiring': 979,\n",
       " 'whole': 980,\n",
       " 'around': 981,\n",
       " 'everyone': 982,\n",
       " 'able': 983,\n",
       " 'walk': 984,\n",
       " 'loudly': 985,\n",
       " 'loud': 986,\n",
       " 'allowed': 987,\n",
       " 'dicing': 988,\n",
       " 'pepper': 989,\n",
       " 'orange': 990,\n",
       " 'diced': 991,\n",
       " 'dices': 992,\n",
       " 'cast': 993,\n",
       " 'cook': 994,\n",
       " 'win': 995,\n",
       " 'rapidly': 996,\n",
       " 'bell': 997,\n",
       " 'peppers': 998,\n",
       " 'bells': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "_Y9erOS2jcE9",
    "outputId": "ef871083-1008-4a1c-9bde-61aa86870f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples        : 7872\n",
      "Number of validation samples      : 1968\n",
      "Maximum sequence length           : 20\n"
     ]
    }
   ],
   "source": [
    "print('Number of training samples        :', len(data.x_train))\n",
    "print('Number of validation samples      :', len(data.x_val))\n",
    "print('Maximum sequence length           :', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_rn2-1xjcE_"
   },
   "outputs": [],
   "source": [
    "embd_file = \"../glove-global-vectors-for-word-representation/glove.6B.100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbDQBbW8jcFC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HERSH\\Miniconda3\\envs\\pytorch_test\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from embedding_helper import Get_Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fnO4rIh6jcFE"
   },
   "outputs": [],
   "source": [
    "embedding = Get_Embedding(embd_file, data.word2index)\n",
    "embedding_size = embedding.embedding_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8CdmMYJCjcFG",
    "outputId": "953049b7-2d49-49ec-8d4f-d97fe7bd64e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wDrorlFIjcFJ",
    "outputId": "6da944df-e2aa-4d14-bca3-6018f44c9db7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2309"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding.embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPpaUlp-jcFM"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0C4dLIfEjcFO",
    "outputId": "38dd76c4-4b15-4bb6-ba92-0381dda37979"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "stopNos = []\n",
    "for i in range(len(data.index2word)):\n",
    "    if data.index2word[i] in stops:\n",
    "        stopNos.append(i)\n",
    "        \n",
    "stopNos\n",
    "print(len(stopNos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3bi1BNwcjcFR"
   },
   "outputs": [],
   "source": [
    "def commonWords(sen_1, sen_2):\n",
    "    listPairs = []\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for i in range(len(sen_1)):\n",
    "        for j in range(len(sen_2)):\n",
    "            if sen_1[i] in stopNos:\n",
    "                continue\n",
    "            \n",
    "            if sen_1[i] != 0:\n",
    "                if sen_1[i] == sen_2[j]:\n",
    "                    list1.append(i)\n",
    "                    list2.append(j)\n",
    "    \n",
    "    list1 = list(dict.fromkeys(list1))\n",
    "    list2 = list(dict.fromkeys(list2))\n",
    "    listPairs.append(list1)\n",
    "    listPairs.append(list2)\n",
    "    return listPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "klC-DZwpgja0"
   },
   "outputs": [],
   "source": [
    "def max_pool(e_list):\n",
    "  e_list = np.array(e_list)\n",
    "  \n",
    "  for i in range(len(e_list)):\n",
    "    e_list[i] = e_list[i].data.cpu().numpy()\n",
    "  mp = []\n",
    "  for i in range(100):\n",
    "    m = e_list[0][i]\n",
    "    for j in range(len(e_list)):\n",
    "      m = max(m, e_list[j][i])\n",
    "    mp.append(m)\n",
    "      \n",
    "  #print(\"Length of mp = \" + str(len(mp)))\n",
    "  return torch.cuda.FloatTensor(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RyWhvPUrjcFT"
   },
   "outputs": [],
   "source": [
    "class Manhattan_LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, train_embedding = False):\n",
    "        super(Manhattan_LSTM, self).__init__()\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(embedding.shape[0], embedding.shape[1])\n",
    "        self.embedding.weight = nn.Parameter(embedding)\n",
    "        self.input_size = embedding.shape[1]\n",
    "        \n",
    "        self.embedding.weight.requires_grad = train_embedding\n",
    "        \n",
    "        self.lstm_1 = nn.LSTM(self.input_size, self.hidden_size, num_layers=1, bidirectional=True)\n",
    "        self.lstm_2 = nn.LSTM(self.input_size, self.hidden_size, num_layers=1, bidirectional=True)\n",
    "        \n",
    "    def exponent_neg_manhattan_distance(self, x1, x2):\n",
    "        return torch.exp(-torch.sum(torch.abs(x1 - x2), dim=1))\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        #print(input[0])\n",
    "        #print(input[1])\n",
    "        \n",
    "        ip0 = input[0].t()\n",
    "        ip1 = input[1].t()\n",
    "        \n",
    "        commonList = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            listPairs = commonWords(ip0[i], ip1[i])\n",
    "            commonList.append(listPairs)\n",
    "    \n",
    "        commonList = np.array(commonList)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(commonList)\n",
    "        embedded_1 = self.embedding(input[0])\n",
    "        embedded_2 = self.embedding(input[1])\n",
    "        \n",
    "        bs = embedded_1.size()[1]\n",
    "        outputs_1, hidden_1 = self.lstm_1(embedded_1, hidden)\n",
    "        outputs_2, hidden_2 = self.lstm_1(embedded_2, hidden)\n",
    "        \n",
    "        max_pool_1 = F.adaptive_max_pool1d(outputs_1.permute(1,2,0),1).view(batch_size,-1)\n",
    "        max_pool_2 = F.adaptive_max_pool1d(outputs_2.permute(1,2,0),1).view(batch_size,-1)\n",
    "        #print(outputs_1.shape)\n",
    "        \n",
    "        #e1 = torch.tensor([])\n",
    "        ehs_1 = []\n",
    "        for i in range(batch_size):\n",
    "            e_list = []\n",
    "            for j in range(len(commonList[i][0])):\n",
    "              x = commonList[i][0][j]\n",
    "              #print(outputs_1[x][i].shape)\n",
    "              \n",
    "              e_list.append(outputs_1[x][i])\n",
    "            if len(e_list) > 0:\n",
    "              mp1 = max_pool(e_list)\n",
    "            else:\n",
    "              mp1 = torch.zeros(100)\n",
    "              \n",
    "            #torch.cat((e1,mp1), 0, out = e1)\n",
    "            ehs_1.append(mp1.cuda())\n",
    "        \n",
    "        #print(len(e1))\n",
    "        #ehs_1 = np.array(ehs_1)\n",
    "        #print(ehs_1.shape)\n",
    "        \n",
    "        ehs_2 = []\n",
    "        #e2 = torch.tensor([])\n",
    "        for i in range(batch_size):\n",
    "            e_list = []\n",
    "            #print(commonList[i][1])\n",
    "            for j in range(len(commonList[i][1])):\n",
    "              x = commonList[i][1][j]\n",
    "              #print(outputs_1[x][i].shape)\n",
    "              \n",
    "              e_list.append(outputs_2[x][i])\n",
    "            if len(e_list) > 0:\n",
    "              mp2 = max_pool(e_list)\n",
    "            else:\n",
    "              mp2 = torch.zeros(100)\n",
    "              \n",
    "            #torch.cat((e2,mp2), 0, out = e2)\n",
    "            ehs_2.append(mp2.cuda())\n",
    "            \n",
    "        #print(len(e2))\n",
    "        \n",
    "        #print(type(ehs_2[0]))\n",
    "        \n",
    "        ths_1 = torch.zeros(16, 200)\n",
    "        for i in range(batch_size):\n",
    "          ths_1[i] = torch.cat((max_pool_1[i], ehs_1[i]),0)\n",
    "          \n",
    "        ths_2 = torch.zeros(16, 200)\n",
    "        for i in range(batch_size):\n",
    "          ths_2[i] = torch.cat((max_pool_2[i], ehs_2[i]),0)\n",
    "          \n",
    "          \n",
    "        #print(ths_1)\n",
    "        #print(ths_2)\n",
    "        \n",
    "        #print(ths_2.requires_grad)\n",
    "        \n",
    "        similarity_scores = self.exponent_neg_manhattan_distance(ths_1.cuda(), ths_2.cuda())\n",
    "        #similarity_scores = self.exponent_neg_manhattan_distance(max_pool_1, max_pool_2)\n",
    "        \n",
    "        return similarity_scores*5.0\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for name_1, param_1 in self.lstm_1.named_parameters():\n",
    "            if 'bias' in name_1:\n",
    "                nn.init.constant_(param_1, 0.0)\n",
    "            elif 'weight' in name_1:\n",
    "                nn.init.xavier_normal_(param_1)\n",
    "\n",
    "        lstm_1 = self.lstm_1.state_dict()\n",
    "        lstm_2 = self.lstm_2.state_dict()\n",
    "\n",
    "        for name_1, param_1 in lstm_1.items():\n",
    "            # Backwards compatibility for serialized parameters.\n",
    "            if isinstance(param_1, torch.nn.Parameter):\n",
    "                param_1 = param_1.data\n",
    "\n",
    "            lstm_2[name_1].copy_(param_1)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Hidden dimensionality : 2 (h_0, c_0) x Num. Layers * Num. Directions x Batch Size x Hidden Size\n",
    "        result = torch.zeros(2, 2, batch_size, self.hidden_size)\n",
    "        result = tuple(result)\n",
    "\n",
    "        if self.use_cuda: \n",
    "            result = (result[0].cuda(), result[1].cuda())\n",
    "            return result\n",
    "        else: return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g28vMmaYjcFW"
   },
   "outputs": [],
   "source": [
    "model = Manhattan_LSTM(hidden_size, embedding.embedding_matrix, train_embedding=False)\n",
    "if use_cuda: model = model.cuda()\n",
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMl3LLyLjcFZ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from torch import optim\n",
    "import torch.nn.utils.rnn as rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AuMB-N9tjcFc",
    "outputId": "1ec6334a-4825-41a6-c547-a438cfcfca06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7872"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = data.x_train\n",
    "x_val = data.x_val\n",
    "y_train = data.y_train\n",
    "y_val = data.y_val\n",
    "train_samples = len(x_train)\n",
    "val_samples = len(x_val)\n",
    "train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "2blp8881jcFg",
    "outputId": "fbff6e39-e9da-4204-81a9-a6b4ca758df1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([  14,  105,    5,  848,   80, 1011,    9, 1330, 1318], device='cuda:0'), tensor([   1,  105,    5,  772,    1, 1329, 1318, 1319], device='cuda:0')]\n",
      "17\n",
      "[[list([1, 8]) list([1, 6])]\n",
      " [list([1, 3, 6, 7, 10, 13]) list([1, 3, 6, 7, 11, 10])]\n",
      " [list([1, 6]) list([1, 6])]\n",
      " [list([4, 6]) list([3, 5])]\n",
      " [list([1, 3, 6, 9]) list([1, 3, 5, 11])]\n",
      " [list([1, 2, 4, 6, 8]) list([3, 4, 5, 7, 9])]\n",
      " [list([1, 7]) list([1, 5])]\n",
      " [list([1, 3]) list([1, 3])]\n",
      " [list([1, 2, 4, 6, 10, 12, 13, 15]) list([1, 2, 13, 4, 6, 10, 12, 16])]\n",
      " [list([1, 2, 3, 4, 5, 10, 11]) list([1, 2, 10, 3, 4, 5, 9])]\n",
      " [list([0, 5]) list([1, 8])]\n",
      " [list([1, 7]) list([1, 6])]\n",
      " [list([1, 4, 6, 8]) list([1, 3, 5, 7])]\n",
      " [list([3, 4, 5, 7, 8, 10, 12]) list([1, 2, 4, 6, 7, 9, 11])]\n",
      " [list([1, 5, 8]) list([7, 1, 10])]\n",
      " [list([1, 6]) list([1, 7])]]\n"
     ]
    }
   ],
   "source": [
    "input_variables = x_train[0:batch_size]\n",
    "print(x_train[0])\n",
    "\n",
    "sequences_1 = [sequence[0] for sequence in input_variables]\n",
    "sequences_2 = [sequence[1] for sequence in input_variables]\n",
    "batch_size = len(sequences_1)\n",
    "\n",
    "temp = rnn.pad_sequence(sequences_1 + sequences_2)\n",
    "sequences_1 = temp[:, :batch_size]\n",
    "sequences_2 = temp[:, batch_size:]\n",
    "\n",
    "ip1 = sequences_1.t()\n",
    "ip2 = sequences_2.t()\n",
    "\n",
    "print(len(ip1[4]))\n",
    "commonList = []\n",
    "\n",
    "for i in range(batch_size):\n",
    "    listPairs = commonWords(ip1[i], ip2[i])\n",
    "    commonList.append(listPairs)\n",
    "    \n",
    "commonList = np.array(commonList)\n",
    "print(commonList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kC8RuPGejcFj"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "print_every = 1\n",
    "print_loss_total = 0.0\n",
    "train_loss = 0.0\n",
    "val_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pNYiWg2rjcFl"
   },
   "outputs": [],
   "source": [
    "model_trainable_parameters = tuple(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "model_optimizer = optim.Adam(model_trainable_parameters, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jp9aPy6JjcFn",
    "outputId": "e8d274e9-c756-46c9-85ab-09b218c436f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = model.init_hidden(batch_size)\n",
    "len(hidden[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89muNWJcjcFp"
   },
   "outputs": [],
   "source": [
    "from helper import Helper\n",
    "help_fn = Helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "ZU2WrGvXjcFr",
    "outputId": "e22c23ec-8d8b-4c19-d1d0-8690eee40817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Model Training.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print('Beginning Model Training.\\n')\n",
    "\n",
    "for epoch in range(0, num_iters):\n",
    "    for i in range(0, train_samples, batch_size):\n",
    "        input_variables = x_train[i:i+batch_size]\n",
    "        similarity_scores = y_train[i:i+batch_size]\n",
    "        \n",
    "        sequences_1 = [sequence[0] for sequence in input_variables]\n",
    "        sequences_2 = [sequence[1] for sequence in input_variables]\n",
    "        batch_size = len(sequences_1)\n",
    "\n",
    "        temp = rnn.pad_sequence(sequences_1 + sequences_2)\n",
    "        sequences_1 = temp[:, :batch_size]\n",
    "        sequences_2 = temp[:, batch_size:]\n",
    "\n",
    "        if model_optimizer: model_optimizer.zero_grad()\n",
    "        loss = 0.0\n",
    "\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        output_scores = model([sequences_1, sequences_2], hidden).view(-1)\n",
    "\n",
    "        loss += criterion(output_scores, similarity_scores)\n",
    "        \n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "        \n",
    "        train_loss = loss\n",
    "        print_loss_total += loss\n",
    "     \n",
    "    \n",
    "    if epoch % 5:\n",
    "        learning_rate *= 0.8\n",
    "        model_optimizer = optim.Adam(model_trainable_parameters, lr=learning_rate)\n",
    "        \n",
    "    for i in range(0, val_samples, batch_size):\n",
    "        input_variables = x_val[i:i+batch_size]\n",
    "        actual_scores = y_val[i:i+batch_size]\n",
    "\n",
    "        sequences_1 = [sequence[0] for sequence in input_variables]\n",
    "        sequences_2 = [sequence[1] for sequence in input_variables]\n",
    "        batch_size = len(sequences_1)\n",
    "\n",
    "        temp = rnn.pad_sequence(sequences_1 + sequences_2)\n",
    "        sequences_1 = temp[:, :batch_size]\n",
    "        sequences_2 = temp[:, batch_size:]\n",
    "\n",
    "        loss = 0.0\n",
    "        \n",
    "\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        output_scores = model([sequences_1, sequences_2], hidden).view(-1)\n",
    "        \n",
    "        loss += criterion(output_scores, actual_scores)\n",
    "        \n",
    "        val_loss = loss\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print('%s (%d) %.4f' % (help_fn.time_slice(start, (epoch+1) / num_iters), epoch, print_loss_avg))\n",
    "        print(\"Training loss    \" + str(train_loss.data.cpu().numpy()) + \"    Validation loss:    \" + str(val_loss.data.cpu().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LS6fgTdfjcFt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_diff = 0.0\n",
    "a_scores = []\n",
    "p_scores = []\n",
    "for i in range(0, val_samples, batch_size):\n",
    "    input_variables = x_val[i:i+batch_size]\n",
    "    actual_scores = y_val[i:i+batch_size]\n",
    "    \n",
    "    sequences_1 = [sequence[0] for sequence in input_variables]\n",
    "    sequences_2 = [sequence[1] for sequence in input_variables]\n",
    "    batch_size = len(sequences_1)\n",
    "\n",
    "    temp = rnn.pad_sequence(sequences_1 + sequences_2)\n",
    "    sequences_1 = temp[:, :batch_size]\n",
    "    sequences_2 = temp[:, batch_size:]\n",
    "\n",
    "    if model_optimizer: model_optimizer.zero_grad()\n",
    "    loss = 0.0\n",
    "\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    output_scores = model([sequences_1, sequences_2], hidden).view(-1)\n",
    "\n",
    "    #loss += criterion(output_scores, similarity_scores)\n",
    "    \n",
    "    \n",
    "    for j in range(0, batch_size):\n",
    "        acts = actual_scores[j].data.cpu().numpy()\n",
    "        preds = output_scores[j].data.cpu().numpy()\n",
    "        a_scores.append(acts)\n",
    "        p_scores.append(preds)\n",
    "        \n",
    "        #pearsonr(np.asarray(pred),label )\n",
    "        #spearmanr(np.asarray(pred),label )\n",
    "        #print(\"Actual score:    \" + str(acts) + \"    Predicted score:    \" + str(preds))\n",
    "        sum_diff+=abs(acts-preds)\n",
    "        \n",
    "    \n",
    "\n",
    "print(len(a_scores))\n",
    "print(pearsonr(p_scores,a_scores))\n",
    "print(spearmanr(p_scores,a_scores))\n",
    "print(sklearn.metrics.mean_squared_error(p_scores, a_scores))\n",
    "print(\"Sum of abs differences:    \" + str(sum_diff) + \"    Deviation:    \" + str(sum_diff/val_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHRUjsg9jcFw"
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "networkSICK.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
